
<!DOCTYPE html>
<html lang="zh-CN" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>&lt;&lt;Python深度学习&gt;&gt;笔记 - 如是</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="Fechin,"> 
    <meta name="description" content="数据预处理数据预处理的目的是使原始数据更适于用神经网络处理，包括向量化、标准化、处理缺失值和特征提取。
数据向量化不能将整数序列直接输入网络，需要将列表转换为张量。转换方法有两种：

填充列表，使其,"> 
    <meta name="author" content="如是"> 
    <link rel="alternative" href="atom.xml" title="如是" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.jpg"> 
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

    
<link rel="stylesheet" href="/css/diaspora.css">

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head>

<body class="loading">
    <span id="config-title" style="display:none">如是</span>
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="iconfont icon-home image-icon" href="javascript:;" data-url="http://example.com"></a>
    <div title="播放/暂停" class="iconfont icon-play"></div>
    <h3 class="subtitle"><<Python深度学习>>笔记</h3>
    <div class="social">
        <div>
            <div class="share">
                <a title="获取二维码" class="iconfont icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>

    <div class="section">
        <div class="article">
    <div class='main'>
        <h1 class="title"><<Python深度学习>>笔记</h1>
        <div class="stuff">
            <span>四月 05, 2021</span>
            
  <ul class="post-tags-list" itemprop="keywords"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/DL/" rel="tag">DL</a></li></ul>


        </div>
        <div class="content markdown">
            <h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>数据预处理的目的是使原始数据更适于用神经网络处理，包括向量化、标准化、处理缺失值和特征提取。<span id="more"></span></p>
<h4 id="数据向量化"><a href="#数据向量化" class="headerlink" title="数据向量化"></a>数据向量化</h4><p>不能将整数序列直接输入网络，需要将列表转换为张量。转换方法有两种：</p>
<ul>
<li><p>填充列表，使其具有相同的长度，再将列表转换为<code>(samples, word_indices)</code>的整数张量，然后网络第一层使用能处理这种整数张量的层，即Embedding层。</p>
<p>词嵌入是先将单词与整数序列构成映射，再对整数序列进行处理，<code>one-hot</code>编码是二进制的、高维的、稀疏的，而词嵌入是从数据中学习到的，是低维的浮点数向量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Embedding</span><br><span class="line"><span class="comment"># 1000是索引的数量，64是嵌入维度，20是最大输入长度，将在此长度后截断文本。</span></span><br><span class="line">embedding_layer = Embedding(<span class="number">1000</span>, <span class="number">64</span>, input_length = <span class="number">20</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>对列表进行<code>one-hot</code>编码，将其转换为0和1组成的向量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此方法适用于无序性的整数列表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_sequences</span>(<span class="params">sequences, dimension = <span class="number">10000</span></span>):</span></span><br><span class="line">    results = np.zeros((<span class="built_in">len</span>(sequences), dimension))</span><br><span class="line">    <span class="keyword">for</span> i, sequence <span class="keyword">in</span> sequences:</span><br><span class="line">        results[i, sequence] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>]])</span><br><span class="line">vec_x = vectorize_sequences(x, <span class="number">10</span>)</span><br><span class="line"><span class="comment">#array([[0., 1., 1., 1., 1.， 0., 0., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#       [0., 1., 1., 1., 1.， 0., 0., 0., 0., 0.]])</span></span><br><span class="line">      </span><br><span class="line"><span class="comment"># 有序性的列表可用 keras 内置的to_categorical方法</span></span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line">labels = array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line">one_host_labels = to_categorical(labels)</span><br><span class="line"></span><br><span class="line"><span class="comment">#array([[ 1.,  0.,  0.],</span></span><br><span class="line"><span class="comment">#       [ 0.,  0.,  1.],</span></span><br><span class="line"><span class="comment">#       [ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment">#       [ 0.,  0.,  1.],</span></span><br><span class="line"><span class="comment">#       [ 1.,  0.,  0.]], dtype=float32)</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="值标准化"><a href="#值标准化" class="headerlink" title="值标准化"></a>值标准化</h4><p>一般来说，将取值相对较大的数据（比如多位整数，比网络权重的初始值大很多）或异质数据（比如数据的一个特征在<code>0~1</code>范围内，另一个特征在<code>100~200</code>内）输入到神经网络中是不安全的。这么可能导致较大的梯度更新，进而导致网络无法收敛。所以输入数据应该具有以下特征：</p>
<ul>
<li><p>取值较小：大部分值应该在0~1范围内</p>
</li>
<li><p>同质性：所有特征的取值都应该在大致相同的范围内</p>
</li>
<li><p>更严格的标准化方法：</p>
<ul>
<li><p>对每个特征分别标准化，使其平均值为0</p>
</li>
<li><p>对每个特征分别标准化，使其标准差为1</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x -= x.mean(axis = <span class="number">0</span>)</span><br><span class="line">x /= x.std(axis = <span class="number">0</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h4 id="处理缺失值"><a href="#处理缺失值" class="headerlink" title="处理缺失值"></a>处理缺失值</h4><p>一般来说，对于神经网络，将缺失值设置为0是安全的，只要0不是一个有意义的值，网络能够从数据中学到0意味着缺失数据，并且会忽略这个值。</p>
<h2 id="过拟合与欠拟合"><a href="#过拟合与欠拟合" class="headerlink" title="过拟合与欠拟合"></a>过拟合与欠拟合</h2><p>优化是指调节模型以在训练数据上得到最佳性能，泛化是指训练好的模型在前所未见的数据上的性能好坏（学习是对于训练数据的学习，而调节参数是以验证数据为标准的，也可能会导致对验证数据的过拟合）。</p>
<h4 id="减小网络大小"><a href="#减小网络大小" class="headerlink" title="减小网络大小"></a>减小网络大小</h4><p>防止过拟合最简单的方法就是减小模型大小，即减少模型中可学习参数的个数。在深度学习中，模型可学习参数的个数通常被称为模型的容量。参数更多的模型拥有更大的记忆容量，因此能够在训练样本和目标之间轻松学会完美映射， 但同时也会导致过拟合。</p>
<p>要找到合适的模型大小，一般的工作流程是开始选择相对较少的层和参数，然后逐渐增加层的大小或增加新层，直到这种增加对验证损失的影响变得很小。</p>
<h4 id="添加权重正则化"><a href="#添加权重正则化" class="headerlink" title="添加权重正则化"></a>添加权重正则化</h4><p>一般来说，简单模型比复杂模型更不容易过拟合。一种常见过拟合方法是权重衰减，在学习过程中对大的权重进行惩罚，来抑制过拟合。添加权重正则化，即向网络损失函数中添加与较大权重值相关的成本，这个成本一般有两种形式：</p>
<ul>
<li><strong><code>L1</code>正则化：</strong> 添加的成本与权重系数的绝对值成正比（<code>L1</code>范数）</li>
<li><strong><code>L2</code>正则化：</strong> 添加的成本与权重系数的平方成正比（<code>L2</code>范数）。神经网络的<code>L2</code>范数也叫权重衰减。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> regularizers</span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, kernel_regularizer = regularizers.l2(<span class="number">0.001</span>) ))</span><br><span class="line"><span class="comment"># 0.001是控制正则化强度的超参数，该层的权重矩阵的每个系数都会使网络总损失增加 0.001 * weight_coefficient_value,</span></span><br><span class="line"><span class="comment"># 需要注意的是这个惩罚项只在训练时添加，所以这个网络的训练损失会比测试损失大很多。</span></span><br></pre></td></tr></table></figure>

<h4 id="添加dropout正则化"><a href="#添加dropout正则化" class="headerlink" title="添加dropout正则化"></a>添加dropout正则化</h4><p>对某一层使用dropout，就是在训练过程中随机将该层的一些输出特征舍弃。dropout比率是被设为0的特征所占的比率，通常在0.2~0.5范围内。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation = <span class="string">&#x27;relu&#x27;</span>, input_shape = (<span class="number">10000</span>, )))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation = <span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation = <span class="string">&#x27;sigmoid&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h4 id="批标准化BatchNormalization"><a href="#批标准化BatchNormalization" class="headerlink" title="批标准化BatchNormalization"></a>批标准化<code>BatchNormalization</code></h4><p>前面的标准化是在将数据输入到网络时对其做标准化，这里的批标准化是在网络的每一次变换后对输出数据做标准化。其原理是，训练过程中在内部保存已读取每批数据均值和方差的指数移动平均值。有助于梯度传播，因此允许更深的网络。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation = <span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">32</span>, activation = <span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br></pre></td></tr></table></figure>

<h4 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h4><p>过拟合的原因是学习样本太少，导致无法训练处能够泛化到新数据的模型。数据增强是从现有的训练样本中生成更多的训练数据，其方法是利用多种能够生成可信图像的随机变换来增加样本。其目标是，模型在训练时不会两次查看完全相同的图像。</p>
<p><code>keras.preprocessing.image</code>中内置了<code>ImageDataGenerator</code>类，其可以通过实例对读取的图像执行多次随机变换来实现数据增强：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用数据增强</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化</span></span><br><span class="line">train_datagen = ImageDataGenerator(rescale = <span class="number">1.</span>/<span class="number">255</span>, <span class="comment"># 图像缩放比例</span></span><br><span class="line">                                  rotation_range = <span class="number">40</span>, <span class="comment"># 角度值，表示图像随机旋转的角度范围</span></span><br><span class="line">                                  <span class="comment"># 图像在水平和垂直方向上相对于总宽度或总高度的比例移动的范围</span></span><br><span class="line">                                  width_shift_range = <span class="number">0.2</span>, </span><br><span class="line">                                  height_shift_range = <span class="number">0.2</span>,</span><br><span class="line">                                  shear_range = <span class="number">0.2</span>, <span class="comment"># 随机错切变换的角度</span></span><br><span class="line">                                  zoom_range = <span class="number">0.2</span>, <span class="comment"># 图像随机缩放的范围</span></span><br><span class="line">                                  horizontal_flip = <span class="literal">True</span>) <span class="comment"># 随机将一半图像水平翻转</span></span><br><span class="line"><span class="comment"># 申城器</span></span><br><span class="line">train_generator = train_datagen.flow_from_directory(train_dir, </span><br><span class="line">                                                  target_size = (<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">                                                  batch_size = <span class="number">32</span>,</span><br><span class="line">                                                  class_mode = <span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line"><span class="comment"># train_dir : 加载的文件目录，会将该目录下的每个子文件夹划为一类</span></span><br><span class="line"><span class="comment"># target_size : 图像大小调整</span></span><br><span class="line"><span class="comment"># batch_size : 批量大小</span></span><br><span class="line"><span class="comment"># class_mode ：&quot;categorical&quot;, &quot;binary&quot;, &quot;sparse&quot;, &quot;input&quot; 或 None 之一。默认：&quot;categorical&quot;。决定返回的标签数组的类型</span></span><br><span class="line">hist = model.fit_generator(train_generator,</span><br><span class="line">                          steps_per_epoch = <span class="built_in">len</span>(train_generator), <span class="comment"># 每一轮（epoch）提取多少批次</span></span><br><span class="line">                          epochs = <span class="number">100</span>,</span><br><span class="line">                          validation_data = val_generator,</span><br><span class="line">                          validation_steps = <span class="built_in">len</span>(val_generator))</span><br></pre></td></tr></table></figure>





<h4 id="K折交叉验证"><a href="#K折交叉验证" class="headerlink" title="K折交叉验证"></a>K折交叉验证</h4><p>如果留出的验证数据过少，无法保证验证结果的可靠性，那么应该选择这种方法来验证模型。</p>
<p>这种方法将可用数据划分为K（通常取4或5）个分区，实例化K个相同的模型，将每个模型在K-1个分区上训练，并在剩下的一个分区上进行评估，模型的验证分数等于K个验证分数的平均值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">k = <span class="number">4</span> </span><br><span class="line">num_val_samples = <span class="built_in">len</span>(train_data) // k <span class="comment"># 每个分区大小</span></span><br><span class="line">num_epochs = <span class="number">100</span></span><br><span class="line">all_scores = [] <span class="comment"># 存储每次验证的分数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">  <span class="built_in">print</span> (<span class="string">&#x27;processing fold #&#x27;</span>, i)</span><br><span class="line">  <span class="comment"># 选择第i个分区作为验证分区</span></span><br><span class="line">  val_data = train_data[i * num_val_samples : (i+<span class="number">1</span>) * num_val_samples]</span><br><span class="line">  val_targets = train_targets[i * num_val_samples : (i+<span class="number">1</span>) * num_val_samples]</span><br><span class="line">  <span class="comment"># 将剩下的分区合并，作为训练数据</span></span><br><span class="line">  partial_train_data = np.concatenate([train_data[: i * num_val_samples], train_data[(i+<span class="number">1</span>) * num_val_samples :]], axis = <span class="number">0</span>)</span><br><span class="line">  partial_train_targets = np.concatenate([train_targets[: i * num_val_samples], train_targets[(i+<span class="number">1</span>) * num_val_samples :]], axis = <span class="number">0</span>)</span><br><span class="line">  </span><br><span class="line">  model = build_model()</span><br><span class="line">  model.fit(partial_train_data,</span><br><span class="line">           partial_train_targets,</span><br><span class="line">           epochs = num_epochs,</span><br><span class="line">           batch_size = <span class="number">1</span>,</span><br><span class="line">           verbose = <span class="number">0</span>)</span><br><span class="line">  </span><br><span class="line">  val_mse, val_mae = model.evaluate(val_data,</span><br><span class="line">                                   val_targets,</span><br><span class="line">                                   verbose = <span class="number">0</span>)</span><br><span class="line">  </span><br><span class="line">  all_scores.append(val_mae)</span><br></pre></td></tr></table></figure>

<h2 id="模型搭建"><a href="#模型搭建" class="headerlink" title="模型搭建"></a>模型搭建</h2><ul>
<li><p>最后一层的激活和损失函数</p>
<table>
<thead>
<tr>
<th>问题类型</th>
<th>最后一层激活函数</th>
<th>损失函数</th>
</tr>
</thead>
<tbody><tr>
<td>二分类问题</td>
<td><code>sigmoid</code></td>
<td><code>binary_crossentropy</code></td>
</tr>
<tr>
<td>多分类、单标签问题</td>
<td><code>softmax</code></td>
<td><code>categorical_crossentropy</code></td>
</tr>
<tr>
<td>多分类、多标签问题</td>
<td><code>sigmoid</code></td>
<td><code>binary_crossentropy</code></td>
</tr>
<tr>
<td>回归到任意值</td>
<td><code>无</code></td>
<td><code>mse</code></td>
</tr>
<tr>
<td>回归到0~1范围内的值</td>
<td><code>sigmoid</code></td>
<td><code>mse</code>或<code>binary_crossentropy</code></td>
</tr>
</tbody></table>
</li>
<li><p>优化配置：大多数情况下，使用<code>rmspropy</code>及其默认的学习率是稳妥的</p>
</li>
</ul>
<h2 id="使用预训练的卷积神经网络"><a href="#使用预训练的卷积神经网络" class="headerlink" title="使用预训练的卷积神经网络"></a>使用预训练的卷积神经网络</h2><p>预训练网络是一个保存好的网络，之前已在大型数据集上训练好。如果这个原始数据集足够大且足够通用，那么预训练网络学到的特征的空间层次结构可以有效地作为视觉世界的通用模型，因此这些特征可用于各种不同的计算机视觉问题。</p>
<p>使用预训练网络的两种方法：</p>
<ul>
<li><p><strong>特征提取</strong></p>
<p>图像分类的卷积神经网络包含两部分：首先是一系列池化层和卷积层，叫做模型的<strong>卷积基</strong>，最后是一个密集连接分类器。特征提取就是取出之前训练好的卷积基，将其冻结，在上面运行新数据，然后在输出上面训练一个新的分类器。</p>
<p><code>VGG16</code>等模型内置于<code>Keras</code>中，可以从<code>keras.applications</code>模块中导入。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">conv_base = VGG16(weights = <span class="string">&#x27;imagenet&#x27;</span>, <span class="comment"># 指定模型初始化的权重检查点</span></span><br><span class="line">                 include_top = <span class="literal">False</span>, <span class="comment"># 指定模型最后是否包含密集连接分类器</span></span><br><span class="line">                 input_shape = (<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)) <span class="comment"># 输入到网络中的图形张量的形状，若不选，则网络可处理任意形状</span></span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(conv_base)</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation = <span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation = <span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 冻结卷积基</span></span><br><span class="line">conv_base.trainable = <span class="literal">False</span></span><br></pre></td></tr></table></figure></li>
<li><p>微调模型</p>
<p>模型微调与特征提取互为补充。对于用于特征提取的冻结的模型基，微调是指将后面的几层或者说顶部的几层（类似栈）“解冻”，并将解冻的几层和新增加的部分联合训练。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方法是冻结部分卷积基</span></span><br><span class="line"></span><br><span class="line">conv_base = VGG16(weights = <span class="string">&#x27;imagenet&#x27;</span>,</span><br><span class="line">                 include_top = <span class="literal">False</span>,</span><br><span class="line">                 input_shape = (<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(conv_base)</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation = <span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation = <span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将除了block5之外的部分冻结</span></span><br><span class="line">set_trainabel = <span class="literal">False</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> conv_base.layers:</span><br><span class="line">  <span class="keyword">if</span> layer.name == <span class="string">&#x27;block5_conv1&#x27;</span>:</span><br><span class="line">    set_trainable = <span class="literal">True</span></span><br><span class="line">  layer.trainable = set_trainable</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="多输入模型"><a href="#多输入模型" class="headerlink" title="多输入模型"></a>多输入模型</h2><p>在这里用一个多输入模型示例——问答模型。</p>
<p>两个输入，一个自然语言描述的问题和一个文本片段，文本片段用作回答的参考文本。一个输出，输出回答。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> Input</span><br><span class="line"></span><br><span class="line">text_vocabulary_size = <span class="number">10000</span>  <span class="comment"># 参考文本词汇大小</span></span><br><span class="line">question_vocabulary_size = <span class="number">10000</span> <span class="comment"># 问题词汇大小</span></span><br><span class="line">answer_vocabulary_size = <span class="number">500</span> <span class="comment"># 回答词汇大小</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 参考文本输入</span></span><br><span class="line">text_input = Input(shape = (<span class="literal">None</span>,), dtype=<span class="string">&#x27;int32&#x27;</span>, name = <span class="string">&#x27;text&#x27;</span>) </span><br><span class="line">embedded_text = layers.Embedding(text_vocabulary_size, <span class="number">64</span>)(text_input) <span class="comment"># 将参考文本输入嵌入长度为64的向量</span></span><br><span class="line">encoded_text = layers.LSTM(<span class="number">32</span>)(embedded_text) <span class="comment"># 用LSTM将向量编码为单个向量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 问题输入</span></span><br><span class="line">question_input = Input(shape = (<span class="literal">None</span>,), dtype = <span class="string">&#x27;int32&#x27;</span>, name = <span class="string">&#x27;question&#x27;</span>) </span><br><span class="line">embedded_question = layers.Embedding(question_vocabulary_size, <span class="number">32</span>)(question_input) <span class="comment"># 将问题文本嵌入长度为32的向量</span></span><br><span class="line">encoded_question = layers.LSTM(<span class="number">16</span>)(embedded_question) <span class="comment"># 用LSTM将向量编码为单个向量</span></span><br><span class="line"></span><br><span class="line">concatenated = layers.concatenate([encoded_text, encoded_question], axis = <span class="number">1</span>) <span class="comment"># 将编码后的问题和文本连接起来</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 回答</span></span><br><span class="line">answer = layers.Dense(answer_vocabulary_size, activation = <span class="string">&#x27;softmax&#x27;</span>)(concatenated) <span class="comment"># 在连接后的输入上添加一个softmax分类器</span></span><br><span class="line"></span><br><span class="line">model = models.Model([text_input, question_input], answer) <span class="comment"># 模型实例化：需要指定两个输入和一个输出</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer = <span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss = <span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics = [<span class="string">&#x27;acc&#x27;</span>])</span><br></pre></td></tr></table></figure>

<p><img src="https://s2.ax1x.com/2019/07/29/e3k7jJ.png" alt="image"></p>
<h2 id="多输出模型"><a href="#多输出模型" class="headerlink" title="多输出模型"></a>多输出模型</h2><p>模型示例——根据给定数据预测一个人的年龄、性别、收入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用函数式API实现一个三输出模型</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> Input</span><br><span class="line"></span><br><span class="line">vocabulary_size = <span class="number">50000</span></span><br><span class="line">num_income_groups = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">posts_input = Input(shape = (<span class="literal">None</span>,), dtype = <span class="string">&#x27;int32&#x27;</span>, name = <span class="string">&#x27;posts&#x27;</span>)</span><br><span class="line">embedded_posts = layers.Embedding(<span class="number">256</span>, vocabulary_size)(posts_input) <span class="comment"># 编码</span></span><br><span class="line">x = layers.Conv1D(<span class="number">128</span>, <span class="number">5</span>, activation = <span class="string">&#x27;relu&#x27;</span>)(embedded_posts)</span><br><span class="line">x = layers.MaxPooling1D(<span class="number">5</span>)(x)</span><br><span class="line">x = layers.Conv1D(<span class="number">256</span>, <span class="number">5</span>, activation = <span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">x = layers.Conv1D(<span class="number">256</span>, <span class="number">5</span>, activation = <span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">x = layers.MaxPooling1D(<span class="number">5</span>)(x)</span><br><span class="line">x = layers.Conv1D(<span class="number">256</span>, <span class="number">5</span>, activation = <span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">x = layers.Conv1D(<span class="number">256</span>, <span class="number">5</span>, activation = <span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">x = layers.GlobalMaxPooling1D()(x)</span><br><span class="line">x = layers.Dense(<span class="number">128</span>, activation = <span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 三个输出，年龄、收入、性别，并且为之命名</span></span><br><span class="line">age_prediction = layers.Dense(<span class="number">1</span>, name = <span class="string">&#x27;age&#x27;</span>)(x)</span><br><span class="line">income_prediction = layers.Dense(num_income_groups, activation = <span class="string">&#x27;softmax&#x27;</span>, name = <span class="string">&#x27;income&#x27;</span>)(x)</span><br><span class="line">gender_prediction = layers.Dense(<span class="number">1</span>, activation = <span class="string">&#x27;sigmoid&#x27;</span>, name = <span class="string">&#x27;gender&#x27;</span>)(x)</span><br><span class="line"><span class="comment"># 指定一个输入和三个输出</span></span><br><span class="line">model = models.Model(posts_input, [age_prediction, income_prediction, gender_prediction])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer = <span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss = [<span class="string">&#x27;mse&#x27;</span>, <span class="string">&#x27;categorical_crossentropy&#x27;</span>, <span class="string">&#x27;binary_crossentropy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 等效编译，按名称配置损失函数</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer = <span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss = &#123;</span><br><span class="line">                  <span class="string">&#x27;age&#x27;</span>: <span class="string">&#x27;mse&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;income&#x27;</span>: <span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;gender&#x27;</span>: <span class="string">&#x27;binary_crossentropy&#x27;</span></span><br><span class="line">              &#125;)</span><br></pre></td></tr></table></figure>

<p><img src="https://s2.ax1x.com/2019/07/29/e3A9jH.jpg" alt="image"></p>
<h2 id="Inception模块"><a href="#Inception模块" class="headerlink" title="Inception模块"></a><code>Inception</code>模块</h2><p><code>Inception</code>模块最基本的形式包含3~4个分支，首先是一个<code>1x1</code>的卷积，然后是一个<code>3x3</code>的卷积，最后将所得到的特征连接在一起。这种设置有助于网络分别学习空间特征和逐通道的特征。<code>1x1</code>卷积不会将跨空间的特征混合在一起，而是将一个位置的一个通道的信息混合在一起，区分了通道特征学习和空间特征学习。而<code>3x3</code>卷积一次提取9个方块，混合了通道特征学习和空间特征学习。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Inception模块</span></span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> Input</span><br><span class="line"></span><br><span class="line">x = Input(shape = (<span class="literal">None</span>, <span class="literal">None</span>, <span class="number">3</span>))</span><br><span class="line">branch_a = layers.Conv2D(<span class="number">128</span>, (<span class="number">1</span>, <span class="number">1</span>), activation = <span class="string">&#x27;relu&#x27;</span>, strides = <span class="number">2</span>)(x) <span class="comment"># 步幅为2，窗口大小为 1</span></span><br><span class="line"></span><br><span class="line">branch_b = layers.Conv2D(<span class="number">128</span>, (<span class="number">1</span>, <span class="number">1</span>), activation = <span class="string">&#x27;relu&#x27;</span>, strides = <span class="number">1</span>)(x) <span class="comment"># 步幅大小为1（默认便是1，这里是为了对比），窗口大小为1</span></span><br><span class="line">branch_b = layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation = <span class="string">&#x27;relu&#x27;</span>, strides = <span class="number">2</span>)(branch_b) <span class="comment"># 2分支的延续</span></span><br><span class="line"></span><br><span class="line">branch_c = layers.AveragePooling2D((<span class="number">3</span>, <span class="number">3</span>), strides = <span class="number">2</span>)(x)</span><br><span class="line">branch_c = layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation = <span class="string">&#x27;relu&#x27;</span>, strides = <span class="number">1</span>)(branch_c)</span><br><span class="line"></span><br><span class="line">branch_d = layers.Conv2D(<span class="number">128</span>, (<span class="number">1</span>, <span class="number">1</span>), activation = <span class="string">&#x27;relu&#x27;</span>, strides = <span class="number">1</span>)(x)</span><br><span class="line">branch_d = layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation = <span class="string">&#x27;relu&#x27;</span>, strides = <span class="number">1</span>)(branch_d)</span><br><span class="line">branch_d = layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation = <span class="string">&#x27;relu&#x27;</span>, strides = <span class="number">2</span>)(branch_d)</span><br><span class="line"></span><br><span class="line"><span class="comment"># concatenate层用于层的特征联合，是通道的合并，也就是说描述图像本身的特征增加了，而每一特征下的信息没有增加</span></span><br><span class="line">output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">model = models.Model(x, output)</span><br><span class="line"></span><br><span class="line">plot_model(model, to_file = <span class="string">&#x27;Inception_model.png&#x27;</span>, show_shapes = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://s2.ax1x.com/2019/07/29/e3lqDf.png" alt="image"></p>
<h2 id="残差连接"><a href="#残差连接" class="headerlink" title="残差连接"></a>残差连接</h2><p>残差连接是让前面某层的输出作为后面某层的输入，从而在序列网络中有效地创造了一条捷径。<strong>前面层的输出没有与后面层的激活连在一起，而是与后面层的激活相加</strong>（假设形状相同），若是形状不同可以用一个线性变换将前面层的层的激活改变成目标形状。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 残差连接：让前面某层的输出特征图作为后面某层的输入，与后面层的激活相加</span></span><br><span class="line">x = Input(shape = (<span class="number">32</span>, <span class="number">32</span>, <span class="number">128</span>))</span><br><span class="line">y = layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation = <span class="string">&#x27;relu&#x27;</span>, padding = <span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">y = layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation = <span class="string">&#x27;relu&#x27;</span>, padding = <span class="string">&#x27;same&#x27;</span>)(y)</span><br><span class="line">y = layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation = <span class="string">&#x27;relu&#x27;</span>, padding = <span class="string">&#x27;same&#x27;</span>)(y)</span><br><span class="line"><span class="comment"># add层是通道信息的叠加，通道数是不变的，所以接受的层的形状必须相同</span></span><br><span class="line">y = layers.add([y, x]) <span class="comment"># 将原始 x 与 输出特征相加，实现残差连接 （特征图的尺寸相同）</span></span><br><span class="line">model = models.Model(x, y)</span><br><span class="line">plot_model(model, to_file = <span class="string">&#x27;Res1_model.png&#x27;</span>, show_shapes = <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 如果特征图的尺寸不同，则用线性残差连接</span></span><br><span class="line">x = Input(shape = (<span class="literal">None</span>, <span class="literal">None</span>, <span class="number">3</span>))</span><br><span class="line">y = layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation = <span class="string">&#x27;relu&#x27;</span>, padding = <span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line">y = layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation = <span class="string">&#x27;relu&#x27;</span>, padding = <span class="string">&#x27;same&#x27;</span>)(y)</span><br><span class="line">y = layers.MaxPooling2D(<span class="number">2</span>, strides = <span class="number">2</span>)(y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 1 x 1 卷积，将原始x张量线性下采样为与y具有相同的形状</span></span><br><span class="line">residul = layers.Conv2D(<span class="number">128</span>, (<span class="number">1</span>, <span class="number">1</span>), strides = <span class="number">2</span>, padding = <span class="string">&#x27;same&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add层是通道信息的叠加，通道数是不变的，所以接受的层的形状必须相同，这里是先调整相后再叠加</span></span><br><span class="line">y = layers.add([y, residul]) <span class="comment"># 将残差张量与输出特征相加</span></span><br><span class="line">model = models.Model(x, y)</span><br><span class="line">plot_model(model, to_file = <span class="string">&#x27;Res2_model.png&#x27;</span>, show_shapes = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>直接相加：</p>
<p><img src="https://s2.ax1x.com/2019/07/29/e33rOx.png" alt="image"></p>
<p>变换后相加：</p>
<p><img src="https://s2.ax1x.com/2019/07/29/e3356I.png" alt="image"></p>
<h2 id="共享权重"><a href="#共享权重" class="headerlink" title="共享权重"></a>共享权重</h2><p>共享权重即多次重复使用一个层实例。示例——评估两个句子的相似度，两个模型分别学习两个句子是没有道理的，可以用一个LSTM分别学习两个句子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 共享权重</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> Input </span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> plot_model</span><br><span class="line"></span><br><span class="line">lstm = layers.LSTM(<span class="number">32</span>) <span class="comment"># 将一个LSTM实例化一次, 由左右分支输入共同训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建模型的左分支</span></span><br><span class="line">left_input = Input(shape = (<span class="literal">None</span>, <span class="number">128</span>), name = <span class="string">&#x27;left_input&#x27;</span>)</span><br><span class="line">left_output = lstm(left_input)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建模型的右分支， 如果调用已有的层实例，那么就会重复使用它的权重</span></span><br><span class="line">right_input = Input(shape = (<span class="literal">None</span>, <span class="number">128</span>), name = <span class="string">&#x27;right_input&#x27;</span>)</span><br><span class="line">right_output = lstm(right_input)</span><br><span class="line"></span><br><span class="line">merged = layers.concatenate([left_output, right_output], axis = <span class="number">1</span>)</span><br><span class="line">predictions = layers.Dense(<span class="number">1</span>, activation = <span class="string">&#x27;sigmoid&#x27;</span>)(merged)</span><br><span class="line"></span><br><span class="line">model = models.Model([left_input, right_input], predictions)</span><br><span class="line">plot_model(model, to_file = <span class="string">&#x27;share_model.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model.fit([left_data, right_data],</span></span><br><span class="line"><span class="comment">#           targets,</span></span><br><span class="line"><span class="comment">#           epochs = 100)</span></span><br></pre></td></tr></table></figure>

<p><img src="https://s2.ax1x.com/2019/07/29/e3Y0UK.png" alt="image"></p>
<h2 id="回调函数"><a href="#回调函数" class="headerlink" title="回调函数"></a>回调函数</h2><p>回调函数时在调用<code>fit</code>时传入模型的一个对象（即实现特定方法的类实例），它在训练过程中的不同时间点都会被调用。他可以访问关于模型状态与性能的所有可用数据，还可以采取行动：中断训练、保存模型、加载一组不同的权重或改变模型的状态。</p>
<p>用法示例：</p>
<ul>
<li>模型检查点：在训练过程中的不同时间点保存模型的当前权重</li>
<li>提前终止：如果验证损失不再改善，则保存模型并中断训练</li>
<li>在训练过程中动态调节某些参数值：比如优化器的学习率</li>
<li>在训练过程中记录训练指标和验证指标，或将模型学到的表示可视化（这些表示也在不断更新）：训练进度条就是一个回调函数</li>
</ul>
<p><code>ModelCheckpoint</code> 和 <code>EarlayStopping</code>回调函数 : </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> callbacks</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过 fit 的callbacks参数将回调函数传入到模型中，这个参数接收一个回调函数的列表，可以传入任意个数的回调函数</span></span><br><span class="line">callbacks_list = [</span><br><span class="line">                  <span class="comment"># 如果模型不再改善则终端训练</span></span><br><span class="line">                  callbacks.EarlayStopping(</span><br><span class="line">                      monitor = <span class="string">&#x27;acc&#x27;</span>, <span class="comment"># 监控模型的验证精度</span></span><br><span class="line">                      patience = <span class="number">1</span> <span class="comment"># 如果精度在多于一轮的时间内不再改善则中断训练</span></span><br><span class="line">                  ),</span><br><span class="line">                  <span class="comment"># 在每轮过后保存当前权重</span></span><br><span class="line">                  callbacks.ModelCheckpoint(</span><br><span class="line">                      filepath = <span class="string">&#x27;my_model.h5&#x27;</span>, <span class="comment"># 模型保存路径</span></span><br><span class="line">                      monitor = <span class="string">&#x27;val_loss&#x27;</span>, <span class="comment"># 监控指标</span></span><br><span class="line">                      save_best_only = <span class="literal">True</span> <span class="comment"># 仅根据监控指标保存当前最佳模型</span></span><br><span class="line">                  )]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer = <span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss = <span class="string">&#x27;bianry_crossentropy&#x27;</span>,</span><br><span class="line">              metrics = [<span class="string">&#x27;acc&#x27;</span>], <span class="comment"># 回调函数的监控指标中选择了 精度，因此在模型的指标中应该有 精度</span></span><br><span class="line">              )</span><br><span class="line"></span><br><span class="line">model.fit(x_train,</span><br><span class="line">          y_train,</span><br><span class="line">          epochs = <span class="number">10</span>,</span><br><span class="line">          batch_size = <span class="number">32</span>,</span><br><span class="line">          callbacks = callbacks_list,</span><br><span class="line">          validation_data = (x_val, y_val), <span class="comment"># 因为回调函数要监控 验证精度 和 验证损失， 所以需要添加验证数据</span></span><br><span class="line">          ) </span><br></pre></td></tr></table></figure>

<p><code>ReduceLROnPlateau</code> 回调函数 :</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果验证损失不再改善，可以用此回调函数来降低学习率，以跳出“学习平台&quot;</span></span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> callbacks</span><br><span class="line"></span><br><span class="line">callbacks_list = [</span><br><span class="line">                  callbacks.ReduceLROnPlateau(</span><br><span class="line">                      monitor = <span class="string">&#x27;val_loss&#x27;</span>, <span class="comment"># 监控指标</span></span><br><span class="line">                      factor = <span class="number">0.1</span>, <span class="comment"># 触发此回调函数时将学习率除10</span></span><br><span class="line">                      patience = <span class="number">10</span>, <span class="comment"># 10轮内验证损失无改善则触发回调函数</span></span><br><span class="line">                  )</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.fit(x_train,</span><br><span class="line">          y_train,</span><br><span class="line">          epochs = <span class="number">10</span>,</span><br><span class="line">          batch_size = <span class="number">32</span>,</span><br><span class="line">          callbacks = callbacks_list,</span><br><span class="line">          validation_data = (x_val, y_val), <span class="comment"># 因为回调函数要监控 验证损失， 所以需要添加验证数据</span></span><br><span class="line">          ) </span><br></pre></td></tr></table></figure>




            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
                <ul id="audio-list" style="display:none">
                    
                        
                            <li title='0' data-url='http://link.hhtjim.com/163/425570952.mp3'></li>
                        
                    
                        
                            <li title='1' data-url='http://link.hhtjim.com/163/425570952.mp3'></li>
                        
                    
                </ul>
            
        </div>
        
    <div id='gitalk-container' class="comment link"
		data-enable='true'
        data-ae='false'
        data-ci=''
        data-cs=''
        data-r=''
        data-o=''
        data-a=''
        data-d='false'
    >查看评论</div>


    </div>
    
        <div class='side'>
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%90%91%E9%87%8F%E5%8C%96"><span class="toc-number">1.0.1.</span> <span class="toc-text">数据向量化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%80%BC%E6%A0%87%E5%87%86%E5%8C%96"><span class="toc-number">1.0.2.</span> <span class="toc-text">值标准化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E7%BC%BA%E5%A4%B1%E5%80%BC"><span class="toc-number">1.0.3.</span> <span class="toc-text">处理缺失值</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="toc-number">2.</span> <span class="toc-text">过拟合与欠拟合</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%87%8F%E5%B0%8F%E7%BD%91%E7%BB%9C%E5%A4%A7%E5%B0%8F"><span class="toc-number">2.0.1.</span> <span class="toc-text">减小网络大小</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0%E6%9D%83%E9%87%8D%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">2.0.2.</span> <span class="toc-text">添加权重正则化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0dropout%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">2.0.3.</span> <span class="toc-text">添加dropout正则化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%B9%E6%A0%87%E5%87%86%E5%8C%96BatchNormalization"><span class="toc-number">2.0.4.</span> <span class="toc-text">批标准化BatchNormalization</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">2.0.5.</span> <span class="toc-text">数据增强</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#K%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="toc-number">2.0.6.</span> <span class="toc-text">K折交叉验证</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-number">3.</span> <span class="toc-text">模型搭建</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">4.</span> <span class="toc-text">使用预训练的卷积神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E8%BE%93%E5%85%A5%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.</span> <span class="toc-text">多输入模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E8%BE%93%E5%87%BA%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.</span> <span class="toc-text">多输出模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Inception%E6%A8%A1%E5%9D%97"><span class="toc-number">7.</span> <span class="toc-text">Inception模块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5"><span class="toc-number">8.</span> <span class="toc-text">残差连接</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B1%E4%BA%AB%E6%9D%83%E9%87%8D"><span class="toc-number">9.</span> <span class="toc-text">共享权重</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0"><span class="toc-number">10.</span> <span class="toc-text">回调函数</span></a></li></ol>	
        </div>
    
</div>


    </div>
</div>
</body>

<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>


<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/typed.js"></script>
<script src="/js/diaspora.js"></script>


<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">


<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>




</html>
